{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6447651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "RESULTS_DIR = Path('results')\n",
    "FIGS_DIR = Path('notebooks/figures')\n",
    "FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def find_experiments(results_dir: Path = RESULTS_DIR):\n",
    "    experiments = []\n",
    "    if not results_dir.exists():\n",
    "        return experiments\n",
    "    for model_dir in results_dir.iterdir():\n",
    "        if not model_dir.is_dir():\n",
    "            continue\n",
    "        model_name = model_dir.name\n",
    "        for exp_sub in model_dir.iterdir():\n",
    "            if not exp_sub.is_dir():\n",
    "                continue\n",
    "            exp_id = exp_sub.name\n",
    "            experiments.append((model_name, exp_id, exp_sub))\n",
    "    return experiments\n",
    "\n",
    "def load_logs(exp_dir: Path):\n",
    "    logs_file = next(exp_dir.glob('exp_*_logs.csv'), None)\n",
    "    if logs_file is None:\n",
    "        return None\n",
    "    return pd.read_csv(logs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c903b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, count, mean, std, median]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate action-level data across runs per model\n",
    "experiments = find_experiments()\n",
    "action_rows = []\n",
    "for model_name, exp_id, exp_dir in experiments:\n",
    "    logs = load_logs(exp_dir)\n",
    "    if logs is None:\n",
    "        continue\n",
    "    # Expect logs to contain 'action' column and 'reward' and 'episode'/'step'\n",
    "    if 'action' not in logs.columns:\n",
    "        continue\n",
    "    df = logs.copy()\n",
    "    df['model'] = model_name\n",
    "    df['experiment_id'] = exp_id\n",
    "    action_rows.append(df[['model','experiment_id','episode','step','action','reward']])\n",
    "\n",
    "if action_rows:\n",
    "    actions_df = pd.concat(action_rows, ignore_index=True)\n",
    "else:\n",
    "    actions_df = pd.DataFrame(columns=['model','experiment_id','episode','step','action','reward'])\n",
    "\n",
    "# Basic summaries\n",
    "actions_df['action'] = actions_df['action'].astype(float)\n",
    "summary_stats = actions_df.groupby('model')['action'].agg(['count','mean','std','median'])\n",
    "summary_stats = summary_stats.reset_index()\n",
    "summary_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b231b71",
   "metadata": {},
   "source": [
    "### Action distribution plots\n",
    "Below we plot histograms of action values per model to show how frequently models choose charging, discharging, or idling actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f07ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No action logs found under results/ to plot.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "if not actions_df.empty:\n",
    "    models = actions_df['model'].unique()\n",
    "    for i, m in enumerate(models):\n",
    "        plt.subplot(len(models), 1, i+1)\n",
    "        sns.histplot(actions_df[actions_df['model'] == m]['action'], bins=50, kde=False)\n",
    "        plt.title(f'Action distribution: {m}')\n",
    "        plt.xlabel('Action (kW)')\n",
    "        plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS_DIR / 'action_distributions.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No action logs found under results/ to plot.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07094f1c",
   "metadata": {},
   "source": [
    "## Behavior around adverse events (exploratory)\n",
    "We define *adverse events* as steps with reward below a threshold (e.g., the bottom 5% of per-step rewards across all logs). For each adverse event we look at the previous and subsequent actions and classify the policy's response as:\n",
    "- **Continue**: action sign remains the same and magnitude remains > small threshold\n",
    "- **Kill**: subsequent action magnitude is near zero (agent effectively stops)\n",
    "- **Restart**: subsequent action reverses sign (agent switches from charging to discharging or vice versa)\n",
    "\n",
    "This is an operational classification for descriptive analysis only; thresholds are explicitly chosen below and can be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13592be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No logs available to analyze adverse-event behavior.\n"
     ]
    }
   ],
   "source": [
    "# Identify adverse events threshold\n",
    "if not actions_df.empty:\n",
    "    reward_threshold = actions_df['reward'].quantile(0.05)\n",
    "    adverse = actions_df[actions_df['reward'] <= reward_threshold].copy()\n",
    "    # For each adverse row, attempt to find previous and next action in same episode/run\n",
    "    def classify_event(row):\n",
    "        m = row['model']\n",
    "        exp = row['experiment_id']\n",
    "        ep = row['episode']\n",
    "        st = row['step']\n",
    "        df_run = actions_df[(actions_df['model']==m) & (actions_df['experiment_id']==exp) & (actions_df['episode']==ep)]\n",
    "        prev_row = df_run[df_run['step'] == st-1] if st-1 in df_run['step'].values else None\n",
    "        next_row = df_run[df_run['step'] == st+1] if st+1 in df_run['step'].values else None\n",
    "        prev_action = float(prev_row['action'].values[0]) if prev_row is not None and len(prev_row)>0 else np.nan\n",
    "        next_action = float(next_row['action'].values[0]) if next_row is not None and len(next_row)>0 else np.nan\n",
    "        # classification thresholds\n",
    "        zero_thresh = 0.1  # kW threshold to consider action as 'stopped'\n",
    "        # If next action is near zero -> kill\n",
    "        if not np.isnan(next_action) and abs(next_action) <= zero_thresh:\n",
    "            return 'kill'\n",
    "        # If sign flips between prev and next -> restart\n",
    "        if not np.isnan(prev_action) and not np.isnan(next_action) and np.sign(prev_action) != np.sign(next_action) and abs(next_action) > zero_thresh:\n",
    "            return 'restart'\n",
    "        # Otherwise: continue (including when next_action similar sign/magnitude)\n",
    "        return 'continue'\n",
    "\n",
    "    adverse['response'] = adverse.apply(classify_event, axis=1)\n",
    "    behavior_counts = adverse.groupby(['model','response']).size().unstack(fill_value=0)\n",
    "    behavior_counts\n",
    "else:\n",
    "    print('No logs available to analyze adverse-event behavior.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016c5ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No behavior data to display.\n"
     ]
    }
   ],
   "source": [
    "# Plot behavior counts per model (stacked bar)\n",
    "if 'behavior_counts' in globals() and not behavior_counts.empty:\n",
    "    behavior_counts.plot(kind='bar', stacked=True, figsize=(8,4))\n",
    "    plt.title('Policy responses to adverse steps (exploratory classification)')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIGS_DIR / 'behavior_response_counts.png')\n",
    "    plt.show()\n",
    "\n",
    "# Small table: percentage breakdown per model\n",
    "if 'behavior_counts' in globals() and not behavior_counts.empty:\n",
    "    percent = behavior_counts.divide(behavior_counts.sum(axis=1), axis=0).round(3)\n",
    "    percent\n",
    "else:\n",
    "    print('No behavior data to display.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a93e1",
   "metadata": {},
   "source": [
    "---\n",
    "### Notes and limitations\n",
    "- The \n",
    " classification is operational and exploratory: it uses a quantile-based threshold on per-step rewards and a simple sign/magnitude heuristic to classify responses.\n",
    "- These exploratory analyses are intended to generate reproducible observations that can guide deeper investigation. They are not final claims about model safety or robustness.\n",
    "- All artifacts used in this notebook are saved in `results/` and are preserved for audit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
